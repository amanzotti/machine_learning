{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "# initialize K\n",
    "# import kmeans\n",
    "from numpy.core.umath_tests import matrix_multiply as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# initialize K\n",
    "\n",
    "\n",
    "def initialize(X, k):\n",
    "    mu_i = np.random.randint(0, high=np.shape(X)[0], size=k)\n",
    "    return X[mu_i, :]\n",
    "\n",
    "\n",
    "def initialize_kpp(X, k):\n",
    "    mu = np.zeros([k, np.shape(X)[1]])\n",
    "    mu_i = np.random.randint(0, high=np.shape(X)[0])\n",
    "    mu[0, :] = X[mu_i, :]\n",
    "    for i in np.arange(1, k):\n",
    "        D2 = np.array([min([np.linalg.norm(x - m)**2 for m in mu]) for x in X])\n",
    "        probs = D2 / D2.sum()\n",
    "        cumprobs = probs.cumsum()\n",
    "        ind = np.where(cumprobs >= np.random.rand())[0][0]\n",
    "        mu[i, :] = X[ind, :]\n",
    "    return mu\n",
    "\n",
    "\n",
    "def assign(X, mu_list):\n",
    "    distances = np.linalg.norm(X - mu_list[0], axis=1)**2\n",
    "\n",
    "    for i, mu in enumerate(mu_list[1:]):\n",
    "        dist = np.linalg.norm(X - mu, axis=1)**2\n",
    "        distances = np.vstack([distances, dist])\n",
    "    ind_assignment = np.argmin(distances, axis=0)\n",
    "\n",
    "    return ind_assignment\n",
    "\n",
    "\n",
    "def dist_functi(data, indeces, mu, k):\n",
    "    cost_funct = 0\n",
    "    for i in range(k):\n",
    "        distances = np.sum(np.linalg.norm(data[np.where(indeces == i)] - mu[i], axis=1)**2)\n",
    "        cost_funct += distances\n",
    "    return cost_funct\n",
    "\n",
    "\n",
    "def compute_new_mu(data, indeces, K):\n",
    "    mu = np.zeros([K, np.shape(data)[1]])\n",
    "    for i in np.arange(K):\n",
    "        mu[i] = np.mean(data[np.where(indeces == i)], axis=0)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def plot_res(data, ind, k):\n",
    "    plt.figure()\n",
    "    for i in np.arange(k):\n",
    "        plt.scatter(data[np.where(ind[:, 0] == i)][:, 0], data[np.where(ind[:, 0] == i)][:, 1])\n",
    "\n",
    "\n",
    "def run_kmeans(datafile='toydata.txt',  init='k++', k=3, iterate=20):\n",
    "\n",
    "    data = np.loadtxt(datafile)\n",
    "    k = 3\n",
    "    cost = []\n",
    "\n",
    "    ind_output = np.zeros([np.shape(data)[0], iterate])\n",
    "\n",
    "    for i in np.arange(iterate):\n",
    "\n",
    "        if init == 'k++':\n",
    "            mu = initialize_kpp(data, k)\n",
    "        else:\n",
    "            mu = initialize(data, k)\n",
    "\n",
    "        flag = 0\n",
    "        cost_internal = []\n",
    "        while flag == 0:\n",
    "            ind = assigne(data, mu)\n",
    "            cost_internal.append(dist_functi(data, ind, mu, k))\n",
    "            new_mu = compute_new_mu(data, ind, k)\n",
    "            if np.array_equal(new_mu, mu):\n",
    "                flag = 1\n",
    "            mu = new_mu\n",
    "        ind_output[:, i] = ind\n",
    "        cost.append([cost_internal])\n",
    "    return cost, ind_output\n",
    "\n",
    "\n",
    "def run_kmeans_bench(data,  init='k++', k=3, iterate=20):\n",
    "\n",
    "    k = 3\n",
    "\n",
    "    ind_output = np.zeros([np.shape(data)[0], iterate])\n",
    "    for i in np.arange(iterate):\n",
    "\n",
    "        if init == 'k++':\n",
    "            mu = initialize_kpp(data, k)\n",
    "        else:\n",
    "            mu = initialize(data, k)\n",
    "        flag = 0\n",
    "        while flag == 0:\n",
    "            ind = assigne(data, mu)\n",
    "            new_mu = compute_new_mu(data, ind, k)\n",
    "            if np.array_equal(new_mu, mu):\n",
    "                flag = 1\n",
    "            mu = new_mu\n",
    "        ind_output[:, i] = ind\n",
    "    return ind_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n interations', 7)\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('toydata.txt')\n",
    "plt.figure(1)\n",
    "plt.figure(2)\n",
    "k = 3\n",
    "mu = initialize_kpp(data, k)\n",
    "flag = 0\n",
    "cost = []\n",
    "while flag == 0:\n",
    "    ind = assign(data, mu)\n",
    "    cost.append(dist_functi(data, ind, mu, k))\n",
    "    new_mu = compute_new_mu(data, ind, k)\n",
    "    if np.array_equal(new_mu, mu):\n",
    "        flag = 1\n",
    "    mu = new_mu\n",
    "\n",
    "print('n interations', len(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize(X, k):\n",
    "    pi = np.random.rand(k)\n",
    "    pi /= np.sum(pi)\n",
    "    mu = kmeans.initialize_kpp(X, k)\n",
    "    sigmas = np.array([np.eye(2)] * k)\n",
    "    return pi, mu, sigmas\n",
    "\n",
    "\n",
    "def plot_models(xs, pis1, mus1, sigmas1):\n",
    "    intervals = 101\n",
    "    ys = np.linspace(-8, 8, intervals)\n",
    "    X, Y = np.meshgrid(ys, ys)\n",
    "    _ys = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    ind = np.zeros([np.shape(xs)[0], 3])\n",
    "    z = np.zeros(len(_ys))\n",
    "    for i, (pi, mu, sigma) in enumerate(zip(pis1, mus1, sigmas1)):\n",
    "        z += pi * mvn(mu, sigma).pdf(_ys)\n",
    "        ind[:, i] = pi * mvn(mu, sigma).pdf(xs)\n",
    "\n",
    "    indeces = np.argmax(ind, axis=1)\n",
    "    z = z.reshape((intervals, intervals))\n",
    "\n",
    "    # find indeces to make plot\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    plt.scatter(mus1[:, 0], mus1[:, 1], alpha=1., c='r', marker='d', s=80)\n",
    "\n",
    "    plt.scatter(xs[np.where(indeces == 0), 0], xs[np.where(indeces == 0), 1], alpha=0.5, c='b')\n",
    "    plt.scatter(xs[np.where(indeces == 1), 0], xs[np.where(indeces == 1), 1], alpha=0.5, c='r')\n",
    "    plt.scatter(xs[np.where(indeces == 2), 0], xs[np.where(indeces == 2), 1], alpha=0.5, c='k')\n",
    "\n",
    "    plt.contour(X, Y, z, N=3)\n",
    "    plt.axis([-6, 8, -6, 6])\n",
    "    ax.axes.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    return 0\n",
    "\n",
    "\n",
    "def MLE_gaussian_mix(data, weights, means, sigmas, tol=0.01, max_iter=100):\n",
    "\n",
    "    n, p = data.shape\n",
    "    k = len(weights)\n",
    "\n",
    "    ll_old = 0\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        like_new = 0\n",
    "\n",
    "        # E-step\n",
    "        ws = np.zeros((k, n))\n",
    "        for j in range(k):\n",
    "            ws[j, :] = weights[j] * mvn(means[j], sigmas[j]).pdf(data)\n",
    "        ws /= ws.sum(0)\n",
    "\n",
    "        # M-step\n",
    "        weights = ws.sum(axis=1)\n",
    "        weights /= n\n",
    "\n",
    "        means = np.dot(ws, data)\n",
    "        # vectorize this in python is damn hard you can do the trick with transpose\n",
    "        # means /= ws.sum(1)[:, None]\n",
    "        means = (means.T / ws.sum(1)).T\n",
    "\n",
    "        sigmas = np.zeros((k, p, p))\n",
    "        for j in range(k):\n",
    "            ys = data - means[j, :]\n",
    "            sigmas[j] = (ws[j, :, None, None] * mm(ys[:, :, None], ys[:, None, :])).sum(axis=0)\n",
    "        sigmas /= ws.sum(axis=1)[:, None, None]\n",
    "\n",
    "        # compute the  likelihoood anc compare\n",
    "        like_new = 0\n",
    "        for pi, mu, sigma in zip(weights, means, sigmas):\n",
    "            like_new += pi * mvn(mu, sigma).pdf(data)\n",
    "        like_new = np.log(like_new).sum()\n",
    "\n",
    "        if np.abs(like_new - ll_old) < tol:\n",
    "            break\n",
    "        ll_old = like_new\n",
    "\n",
    "    return like_new, weights, means, sigmas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('3Ddata.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_3d(x, ind):\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    colors = {1: 'g', 2: 'y', 3: 'b', 4: 'r'}\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for i in np.unique(ind):\n",
    "        ax.scatter(x[np.where(ind == i)][:, 0], x[np.where(ind == i)][:, 1],\n",
    "                   x[np.where(ind == i)][:, 2], c=colors[i], alpha=0.8)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def plot_2d(x, ind):\n",
    "    colors = {1: 'g', 2: 'y', 3: 'b', 4: 'r'}\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    for i in np.unique(ind):\n",
    "        ax.scatter(x[np.where(ind == i)][:, 0], x[np.where(ind == i)][:, 1], c=colors[i], alpha=0.8)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def plot_1d(x, ind):\n",
    "    colors = {1: 'g', 2: 'y', 3: 'b', 4: 'r'}\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    for i in np.unique(ind):\n",
    "        ax.plot(x[np.where(ind == i)][:, 0], c=colors[i], alpha=0.8)\n",
    "    return 0\n",
    "\n",
    "# pca starts here.\n",
    "\n",
    "def pca(x):\n",
    "    # center\n",
    "    x -= np.mean(x, axis=0)\n",
    "    # compute conv\n",
    "    sigma = np.dot(x.T, x) / x.shape[0]\n",
    "    # eigenproblem\n",
    "    values, vectors = np.linalg.eigh(sigma)\n",
    "    # sort them\n",
    "    idx = values.argsort()[::-1]\n",
    "    # eigenValues = values[idx]\n",
    "    eigenVectors = vectors[:, idx]\n",
    "\n",
    "    # project into eigenvector and return\n",
    "    return np.dot(x, eigenVectors[:, :2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = data[:, 0:3]\n",
    "res = pca(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISOMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_matrix(data):\n",
    "    '''\n",
    "    tested\n",
    "    '''\n",
    "    distances = np.zeros([data.shape[0], data.shape[0]])\n",
    "    for (i, pointi) in enumerate(data):\n",
    "        for (j, pointj) in enumerate(data):\n",
    "            distances[i, j] = np.linalg.norm(pointi - pointj)\n",
    "    return distances\n",
    "\n",
    "\n",
    "def set_K_neighboorg(distances, k=10):\n",
    "    '''\n",
    "    tested\n",
    "    '''\n",
    "    output = np.ones_like(distances)\n",
    "    # set not connected to inf\n",
    "    output *= np.inf\n",
    "    np.fill_diagonal(output, 0)\n",
    "\n",
    "    for i in range(distances.shape[0]):\n",
    "        closest = distances[:, i].argsort()[0:k]\n",
    "        # print i, closest\n",
    "        output[i, closest] = distances[i, closest]\n",
    "        # output[closest, i] = distances[closest, i]\n",
    "    return output\n",
    "\n",
    "\n",
    "# apply Floyd algotrithm\n",
    "\n",
    "def shortest_path(distances):\n",
    "    output = distances.copy()\n",
    "    # for i in range(output.shape[0]):\n",
    "    #     output = np.minimum(output, np.add.outer(output[:, i], output[i, :]))\n",
    "\n",
    "    # for k in range(output.shape[0]):\n",
    "    #     for j in range(output.shape[0]):\n",
    "    #         for j in range(output.shape[0]):\n",
    "    #             output[i,j] = min(output[i,j], output[i,k] + output[k,j])\n",
    "    for k in xrange(output.shape[0]):\n",
    "        output = minimum(output, output[newaxis, k, :] + output[:, k, newaxis])\n",
    "\n",
    "    # for k in xrange(output.shape[0]):\n",
    "    #     for i in xrange(output.shape[0]):\n",
    "    #         output[i,:] = minimum(output[i,:], output[i,k] + output[k,:])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# Below all give the same mds tested for debugging\n",
    "\n",
    "\n",
    "\n",
    "# ========= I TRIED DIFFERENT MDS CAUSE IT DID NOT SEEM TO WORK AT FIRST\n",
    "# do MDS on this\n",
    "def mds_run(d, dimensions=2):\n",
    "    '''\n",
    "    not fully tested yet\n",
    "    '''\n",
    "    # create G_tilde from dist\n",
    "\n",
    "    (n, n) = d.shape\n",
    "    # create G_tilde − 1/2 P*D*P\n",
    "    E = (-0.5 * d**2)\n",
    "\n",
    "    # Use mat to get column and row means to act as column and row means.\n",
    "    Er = np.mat(np.mean(E, 1))\n",
    "    Es = np.mat(np.mean(E, 0))\n",
    "\n",
    "    F = array(E - transpose(Er) - Es + mean(E))\n",
    "\n",
    "    [U, S, V] = np.linalg.svd(F)\n",
    "\n",
    "    # create data given the gram matrix using preposition 2\n",
    "\n",
    "    Y = U * np.sqrt(S)\n",
    "\n",
    "    return (Y[:, 0:dimensions], S)\n",
    "\n",
    "\n",
    "# do MDS on this\n",
    "def mds_run_2(data, dimensions=2):\n",
    "\n",
    "    # create G_tilde from data\n",
    "\n",
    "    data -= np.mean(data, axis=0)\n",
    "    F = np.dot(data, data.T)\n",
    "    [U, S, V] = np.linalg.svd(F)\n",
    "\n",
    "    # create data given the gram matrix using preposition 2\n",
    "\n",
    "    Y = U * np.sqrt(S)\n",
    "\n",
    "    return (Y[:, 0:dimensions], S)\n",
    "\n",
    "\n",
    "def cmdscale(D):\n",
    "\n",
    "    # Number of points\n",
    "    n = len(D)\n",
    "\n",
    "    # Centering matrix\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "\n",
    "    # YY^T\n",
    "    B = -H.dot(D**2).dot(H) / 2\n",
    "\n",
    "    # Diagonalize\n",
    "    evals, evecs = np.linalg.eigh(B)\n",
    "\n",
    "    # Sort by eigenvalue in descending order\n",
    "    idx = np.argsort(evals)[::-1]\n",
    "    evals = evals[idx]\n",
    "    evecs = evecs[:, idx]\n",
    "\n",
    "    # Compute the coordinates using positive-eigenvalued components only\n",
    "    w, = np.where(evals > 0)\n",
    "    L = np.diag(np.sqrt(evals[w]))\n",
    "    V = evecs[:, w]\n",
    "    Y = V.dot(L)\n",
    "\n",
    "    return Y, evals\n",
    "\n",
    "\n",
    "def isomap(data, dim=2, k=10):\n",
    "    # compute l2 distances among points\n",
    "    dist = distance_matrix(data)\n",
    "    # convert into a graph with k-neighbourhs\n",
    "    #  deltaij = -inf if not connected\n",
    "    dist_k = set_K_neighboorg(dist, k=k)\n",
    "    # compute shortest path on the graph\n",
    "    geodesic_distance = shortest_path(dist_k)\n",
    "    # apply mds to it\n",
    "    y, s = mds_run(geodesic_distance, dimensions=dim)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def distance_matrix(data):\n",
    "    '''\n",
    "    tested\n",
    "    '''\n",
    "    distances = np.zeros([data.shape[0], data.shape[0]])\n",
    "    for (i, pointi) in enumerate(data):\n",
    "        for (j, pointj) in enumerate(data):\n",
    "            distances[i, j] = np.linalg.norm(pointi - pointj)\n",
    "    return distances\n",
    "\n",
    "\n",
    "def laplacian_eig(data, dim=2, k=10, sigma=0.5):\n",
    "\n",
    "    dist = distance_matrix(data)\n",
    "\n",
    "# build the graph\n",
    "    graph = np.zeros(dist.shape)\n",
    "    L2_dist = dist.copy()\n",
    "# set k neigh connected disconnect the others\n",
    "    for i in np.arange(dist.shape[0]):\n",
    "        dist[i, i] = np.inf\n",
    "        for j in np.arange(k):\n",
    "            idx = dist[i].argmin()\n",
    "            graph[i, idx] = 1.0\n",
    "            graph[idx, i] = graph[i, idx]\n",
    "            dist[i, idx] = np.inf\n",
    "    print np.sum(dist[:,0]!=np.inf)\n",
    "    # Step 2: Choosing the weights using the heat input\n",
    "\n",
    "    nz = np.nonzero(graph)\n",
    "    graph[nz] *= np.exp(-L2_dist[nz]**2 / sigma)\n",
    "\n",
    "    # Laplacian matrix solve Lf=l Df\n",
    "    weight = np.diag(graph.sum(1))\n",
    "    # build laplacian l\n",
    "    laplacian = weight - graph\n",
    "    laplacian[np.isinf(laplacian)] = 0\n",
    "    laplacian[np.isnan(laplacian)] = 0\n",
    "\n",
    "    # Generalized Eigenvalue Decomposition\n",
    "    # generalized problem\n",
    "    val, vec = scipy.linalg.eig(laplacian, weight)\n",
    "    index = np.real(val).argsort()\n",
    "    # leave eigenvector 0 alone and return the firs d after that\n",
    "    return vec[:, index[1:dim + 1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.linalg\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "data = np.loadtxt('3Ddata.txt')\n",
    "x = data[:, 0:3]\n",
    "\n",
    "#! /usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "def distance_matrix(data):\n",
    "    '''\n",
    "    tested\n",
    "    '''\n",
    "    distances = np.zeros([data.shape[0], data.shape[0]])\n",
    "    for (i, pointi) in enumerate(data):\n",
    "        for (j, pointj) in enumerate(data):\n",
    "            distances[i, j] = np.linalg.norm(pointi - pointj)\n",
    "    return distances\n",
    "\n",
    "\n",
    "def lle(data, dim=2, k=10):\n",
    "    # compute L2 distance\n",
    "    dist = distance_matrix(data)\n",
    "\n",
    "    rn = xrange(dist.shape[0])\n",
    "    dist[rn, rn] = np.inf\n",
    "\n",
    "    neigh = dist.argsort(1)\n",
    "\n",
    "    # STEP2: Solve for Reconstruction Weights\n",
    "    # using a linear system is faster than inverting the matrix\n",
    "    tol = 1e-3\n",
    "\n",
    "    W = np.zeros((data.shape[0], k))\n",
    "    for i in xrange(W.shape[0]):\n",
    "        z = data[neigh[i, :k], :] - data[i]\n",
    "        C = np.dot(z, z.T)\n",
    "        # C_inv  = np.linalg.inv(C)\n",
    "        # print np.sum(C_inv,axis=1)/np.sum(C_inv)\n",
    "        # just a bit of tolerance in case it is singular\n",
    "        C = C + np.eye(k) * tol * np.trace(C)\n",
    "        W[i, :] = scipy.linalg.solve(C, np.ones((k, 1))).T\n",
    "        W[i, :] /= W[i, :].sum()\n",
    "\n",
    "\n",
    "    # Compute Embedding from Eigenvects of Cost Matrix M = (1 - W).T (1 - W)\n",
    "\n",
    "    M = np.eye(data.shape[0])\n",
    "    for i in xrange(M.shape[0]):\n",
    "        w = W[i, :]\n",
    "        j = neigh[i, :k]\n",
    "        M[i, j] = M[i, j] - w\n",
    "        M[j, i] = M[j, i] - w\n",
    "        for l in xrange(w.shape[0]):\n",
    "            M[j[l], j] = M[j[l], j] + w[l] * w\n",
    "\n",
    "    # Calculation of Embedding\n",
    "    val, vec = scipy.linalg.eig(M)\n",
    "    index = np.real(val).argsort()\n",
    "    index = index[::-1]\n",
    "\n",
    "    return vec[:, index[-(dim + 1):-1]] * np.sqrt(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIOLA JONES FACE RECOGNITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
